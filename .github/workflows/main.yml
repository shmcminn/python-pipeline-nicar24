# name: Scrape latest data
on:
 workflow_dispatch:
 push:
    branches:
      - main
 schedule:
   - cron:  '0 * * * *'

permissions:
  contents: write
  packages: write

jobs:
 scrape:
   runs-on: ubuntu-latest
   steps:
   # Step 1: Prepare the environment
   - name: Check out this repo
     uses: actions/checkout@v2
     with:
       fetch-depth: 0
       
   # Step 2: Install requirements, so Python script can run
   - name: Install requirements
     # this may change depending on how we handle dependencies
     run: pip install -r requirements.txt
   # Step 3   
   - name: Run scraper
     run: jupyter execute pipeline.ipynb
   # Step 4   
   - name: Commit files
     run: |
       git config remote.origin.url https://github.com/shmcminn/python-pipeline-nicar24.git
       git config --global user.name "$(git --no-pager log --format=format:'%an' -n 1)"
       git config --global user.email "$(git --no-pager log --format=format:'%ae' -n 1)"
       git add .
       git commit -m "Automated commit from GitHub Actions"
       git push origin HEAD:main
    

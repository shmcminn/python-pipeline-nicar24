# name: Scrape latest data

on:
 workflow_dispatch:
 schedule:
   - cron:  '0 * * * *'

jobs:
 scrape:
   runs-on: ubuntu-latest
   steps:
   # Step 1: Prepare the environment
   - name: Check out this repo
     uses: actions/checkout@v2
     with:
       fetch-depth: 0
       persist-credentials: false # otherwise, the token used is the GITHUB_TOKEN, instead of your personal access token.

   # Step 2: Install requirements, so Python script can run
   - name: Install requirements
     # this may change depending on how we handle dependencies
     run: pip install -r requirements.txt
   # Step 3   
   - name: Run scraper
     run: jupyter execute pipeline.ipynb
   # Step 4   
   - name: Commit files
      run: |
       git config remote.origin.url https://github.com/<username>/<repo>.git
       git config --global user.name "$(git --no-pager log --format=format:'%an' -n 1)"
       git config --global user.email "$(git --no-pager log --format=format:'%ae' -n 1)"
       git commit -m "Automated commit from GitHub Actions"
       git push origin HEAD:main
    
